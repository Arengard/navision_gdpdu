---
phase: 05-integration
plan: 01
type: execute
wave: 1
depends_on: ["02-02", "03-01", "04-01"]
files_modified: [src/gdpdu_parser.hpp, src/gdpdu_parser.cpp, src/gdpdu_importer.hpp, src/gdpdu_importer.cpp, src/gdpdu_extension.cpp, src/CMakeLists.txt]
autonomous: true

must_haves:
  truths:
    - "gdpdu_import(path) is registered as a DuckDB table function"
    - "Function parses index.xml from the given directory"
    - "Function creates all tables defined in index.xml"
    - "Function loads data from .txt files into created tables"
    - "Function returns result set with (table_name, row_count, status) per table"
    - "Windows paths with backslashes are handled correctly"
  artifacts:
    - path: "src/gdpdu_parser.hpp"
      provides: "XML parser interface for index.xml"
      min_lines: 15
      contains: "parse_index_xml"
    - path: "src/gdpdu_parser.cpp"
      provides: "XML parser implementation using pugixml"
      min_lines: 80
      contains: "pugi::xml_document"
    - path: "src/gdpdu_importer.hpp"
      provides: "Import orchestrator interface"
      min_lines: 20
      contains: "import_gdpdu"
    - path: "src/gdpdu_importer.cpp"
      provides: "Import orchestrator wiring parser, creator, and loader"
      min_lines: 60
      contains: "create_tables"
    - path: "src/gdpdu_extension.cpp"
      provides: "Extension with registered gdpdu_import table function"
      min_lines: 80
      contains: "gdpdu_import"
  key_links:
    - from: "src/gdpdu_importer.cpp"
      to: "src/gdpdu_parser.hpp"
      via: "calls parse_index_xml"
    - from: "src/gdpdu_importer.cpp"
      to: "src/gdpdu_table_creator.hpp"
      via: "calls create_tables"
    - from: "src/gdpdu_importer.cpp"
      to: "src/gdpdu_data_parser.hpp"
      via: "calls parse_file and inserts rows"
    - from: "src/gdpdu_extension.cpp"
      to: "src/gdpdu_importer.hpp"
      via: "table function calls import_gdpdu"
---

<objective>
Wire all components into a working gdpdu_import() table function.

Purpose: Create the end-to-end import flow — user calls `SELECT * FROM gdpdu_import('path')` and gets all GDPdU tables created and populated in DuckDB, with a result set showing what was imported.

Output: Working extension with registered table function that parses XML, creates tables, loads data, and returns import results.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

Existing components:
@src/gdpdu_schema.hpp — schema structures (TableDef, ColumnDef, GdpduType)
@src/gdpdu_schema.cpp — type conversion helpers
@src/gdpdu_table_creator.hpp — create_tables() interface
@src/gdpdu_table_creator.cpp — table creation implementation
@src/gdpdu_data_parser.hpp — GdpduDataParser class
@src/gdpdu_data_parser.cpp — data parsing implementation
@src/gdpdu_extension.hpp — extension class declaration
@src/gdpdu_extension.cpp — extension entry point (currently minimal)

Build system:
@CMakeLists.txt — root cmake with DuckDB and pugixml
@src/CMakeLists.txt — extension sources

Sample data:
@Gdpdu Data/index.xml — sample GDPdU export for testing
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement XML parser (from Phase 2-02)</name>
  <files>src/gdpdu_parser.hpp, src/gdpdu_parser.cpp, src/include/gdpdu_parser.hpp</files>
  <action>
Create the XML parser that was planned in Phase 2-02 but not yet implemented.

**src/include/gdpdu_parser.hpp**:

```cpp
#pragma once

#include "gdpdu_schema.hpp"
#include <string>

namespace duckdb {

// Parse GDPdU index.xml from a directory path
// Returns GdpduSchema with all table definitions
// Throws std::runtime_error on parse failure
GdpduSchema parse_index_xml(const std::string& directory_path);

} // namespace duckdb
```

**src/gdpdu_parser.cpp**:

1. Include headers:
   - `"gdpdu_parser.hpp"`
   - `<pugixml.hpp>`
   - `<stdexcept>`
   - `<algorithm>` for std::replace

2. Implement path helper to normalize Windows/Unix paths:
   ```cpp
   static std::string normalize_path(const std::string& path) {
       std::string result = path;
       // Normalize to forward slashes
       std::replace(result.begin(), result.end(), '\\', '/');
       // Remove trailing slash
       while (!result.empty() && result.back() == '/') {
           result.pop_back();
       }
       return result;
   }
   
   static std::string join_path(const std::string& dir, const std::string& file) {
       std::string norm_dir = normalize_path(dir);
       if (norm_dir.empty()) {
           return file;
       }
       return norm_dir + "/" + file;
   }
   ```

3. Implement helper `parse_column(xml_node, is_pk)`:
   - Extract name from `<Name>` element
   - Determine type by checking for AlphaNumeric/Numeric/Date child
   - For Numeric, extract precision from `<Accuracy>` sub-element
   - Set is_primary_key flag

4. Implement helper `parse_table(xml_node)`:
   - Extract URL, Name, Description
   - Check for UTF8 element presence
   - Extract DecimalSymbol and DigitGroupingSymbol (default ',' and '.')
   - Navigate to VariableLength child
   - Parse VariablePrimaryKey elements first (in order)
   - Parse VariableColumn elements next (in order)
   - Store primary key column names

5. Implement `parse_index_xml(directory_path)`:
   - Join directory_path with "index.xml"
   - Load XML with pugi::xml_document::load_file
   - Throw runtime_error on parse failure
   - Navigate to DataSet/Media
   - Extract Media/Name
   - Iterate Table children, call parse_table for each
   - Return populated GdpduSchema
  </action>
  <verify>Build succeeds with new parser source</verify>
  <done>XML parser implemented and compiles</done>
</task>

<task type="auto">
  <name>Task 2: Create import orchestrator</name>
  <files>src/include/gdpdu_importer.hpp, src/gdpdu_importer.cpp</files>
  <action>
Create the orchestrator that wires parser → table creator → data loader.

**src/include/gdpdu_importer.hpp**:

```cpp
#pragma once

#include "gdpdu_schema.hpp"
#include "duckdb.hpp"
#include <string>
#include <vector>

namespace duckdb {

// Result of importing a single table
struct ImportResult {
    std::string table_name;
    int64_t row_count;
    std::string status;  // "OK" or error message
    
    ImportResult() : row_count(0), status("") {}
};

// Import all GDPdU tables from a directory
// 1. Parses index.xml
// 2. Creates tables in DuckDB
// 3. Loads data from .txt files
// Returns vector of results for each table
std::vector<ImportResult> import_gdpdu(Connection& conn, const std::string& directory_path);

} // namespace duckdb
```

**src/gdpdu_importer.cpp**:

1. Include headers:
   - `"gdpdu_importer.hpp"`
   - `"gdpdu_parser.hpp"`
   - `"gdpdu_table_creator.hpp"`
   - `"gdpdu_data_parser.hpp"`
   - `<sstream>` for building INSERT SQL

2. Implement path helpers (or reuse from parser via shared header):
   ```cpp
   static std::string normalize_path(const std::string& path);
   static std::string join_path(const std::string& dir, const std::string& file);
   ```

3. Implement helper `insert_rows(conn, table, rows)`:
   - Build INSERT statement with placeholders
   - For each row, build VALUES clause with properly quoted strings
   - Execute batch inserts (e.g., 1000 rows per INSERT for performance)
   - Return rows inserted count

4. Implement `import_gdpdu(conn, directory_path)`:
   ```cpp
   std::vector<ImportResult> import_gdpdu(Connection& conn, const std::string& directory_path) {
       std::vector<ImportResult> results;
       
       // Step 1: Parse index.xml
       GdpduSchema schema;
       try {
           schema = parse_index_xml(directory_path);
       } catch (const std::exception& e) {
           ImportResult r;
           r.table_name = "(schema)";
           r.row_count = 0;
           r.status = std::string("Parse error: ") + e.what();
           results.push_back(r);
           return results;
       }
       
       // Step 2: Create tables
       auto create_results = create_tables(conn, schema);
       
       // Step 3: For each table, load data
       for (size_t i = 0; i < schema.tables.size(); ++i) {
           const auto& table = schema.tables[i];
           ImportResult result;
           result.table_name = table.name;
           
           // Check table creation status
           if (!create_results[i].success) {
               result.row_count = 0;
               result.status = "Create failed: " + create_results[i].error_message;
               results.push_back(result);
               continue;
           }
           
           // Build data file path
           std::string data_path = join_path(directory_path, table.url);
           
           // Parse data file
           DataParseResult parse_result;
           auto rows = GdpduDataParser::parse_file(data_path, table, parse_result);
           
           if (!parse_result.success) {
               result.row_count = 0;
               result.status = "Parse failed: " + parse_result.error_message;
               results.push_back(result);
               continue;
           }
           
           // Insert rows into table
           try {
               insert_rows(conn, table, rows);
               result.row_count = static_cast<int64_t>(rows.size());
               result.status = "OK";
           } catch (const std::exception& e) {
               result.row_count = 0;
               result.status = std::string("Insert failed: ") + e.what();
           }
           
           results.push_back(result);
       }
       
       return results;
   }
   ```

5. For `insert_rows`, implement efficient batch INSERT:
   - Escape single quotes in string values (replace ' with '')
   - Quote all values appropriately (strings in quotes, NULL for empty)
   - Build multi-row INSERT: `INSERT INTO "Table" VALUES (v1, v2), (v3, v4), ...`
   - Execute in batches of ~1000 rows to avoid SQL statement size limits
  </action>
  <verify>Build succeeds with importer source</verify>
  <done>Import orchestrator implemented with parse → create → load flow</done>
</task>

<task type="auto">
  <name>Task 3: Register gdpdu_import table function</name>
  <files>src/gdpdu_extension.cpp</files>
  <action>
Update the extension to register gdpdu_import as a DuckDB table function.

**DuckDB Table Function Pattern:**

A table function in DuckDB requires:
1. Bind function - validates arguments, sets up return columns
2. Init function - initializes state (global and local)
3. Scan function - produces output rows

**Implementation in src/gdpdu_extension.cpp:**

1. Add includes:
   ```cpp
   #include "gdpdu_importer.hpp"
   #include "duckdb/function/table_function.hpp"
   #include "duckdb/main/extension_util.hpp"
   ```

2. Define bind data structure:
   ```cpp
   struct GdpduImportBindData : public TableFunctionData {
       std::string directory_path;
   };
   ```

3. Define global state structure:
   ```cpp
   struct GdpduImportGlobalState : public GlobalTableFunctionState {
       std::vector<ImportResult> results;
       idx_t current_row;
       bool done;
       
       GdpduImportGlobalState() : current_row(0), done(false) {}
   };
   ```

4. Implement bind function:
   ```cpp
   static unique_ptr<FunctionData> GdpduImportBind(
       ClientContext &context,
       TableFunctionBindInput &input,
       vector<LogicalType> &return_types,
       vector<string> &names
   ) {
       auto bind_data = make_uniq<GdpduImportBindData>();
       
       // Get directory path argument
       bind_data->directory_path = input.inputs[0].GetValue<string>();
       
       // Define return columns
       return_types.push_back(LogicalType::VARCHAR);  // table_name
       names.push_back("table_name");
       
       return_types.push_back(LogicalType::BIGINT);   // row_count
       names.push_back("row_count");
       
       return_types.push_back(LogicalType::VARCHAR);  // status
       names.push_back("status");
       
       return std::move(bind_data);
   }
   ```

5. Implement init function:
   ```cpp
   static unique_ptr<GlobalTableFunctionState> GdpduImportInit(
       ClientContext &context,
       TableFunctionInitInput &input
   ) {
       auto state = make_uniq<GdpduImportGlobalState>();
       
       // Get bind data
       auto &bind_data = input.bind_data->Cast<GdpduImportBindData>();
       
       // Create connection and run import
       auto &db = DatabaseInstance::GetDatabase(context);
       Connection conn(db);
       
       state->results = import_gdpdu(conn, bind_data.directory_path);
       state->current_row = 0;
       state->done = state->results.empty();
       
       return std::move(state);
   }
   ```

6. Implement scan function:
   ```cpp
   static void GdpduImportScan(
       ClientContext &context,
       TableFunctionInput &data,
       DataChunk &output
   ) {
       auto &state = data.global_state->Cast<GdpduImportGlobalState>();
       
       if (state.done) {
           return;
       }
       
       idx_t count = 0;
       idx_t max_count = STANDARD_VECTOR_SIZE;
       
       while (state.current_row < state.results.size() && count < max_count) {
           auto &result = state.results[state.current_row];
           
           output.SetValue(0, count, Value(result.table_name));
           output.SetValue(1, count, Value(result.row_count));
           output.SetValue(2, count, Value(result.status));
           
           state.current_row++;
           count++;
       }
       
       output.SetCardinality(count);
       
       if (state.current_row >= state.results.size()) {
           state.done = true;
       }
   }
   ```

7. Register the function in Load():
   ```cpp
   void GdpduExtension::Load(DuckDB &db) {
       // Create table function
       TableFunction gdpdu_import("gdpdu_import", {LogicalType::VARCHAR}, GdpduImportScan, GdpduImportBind, GdpduImportInit);
       
       // Register with extension
       ExtensionUtil::RegisterFunction(*db.instance, gdpdu_import);
       
       std::cout << "GDPdU extension loaded successfully!" << std::endl;
   }
   ```
  </action>
  <verify>Extension compiles without errors</verify>
  <done>gdpdu_import table function registered and callable</done>
</task>

<task type="auto">
  <name>Task 4: Update CMake and verify build</name>
  <files>src/CMakeLists.txt</files>
  <action>
Update CMakeLists to include new source files.

**src/CMakeLists.txt:**

Update EXTENSION_SOURCES to include:
```cmake
set(EXTENSION_SOURCES
    gdpdu_extension.cpp
    gdpdu_schema.cpp
    gdpdu_parser.cpp
    gdpdu_table_creator.cpp
    gdpdu_data_parser.cpp
    gdpdu_importer.cpp
)
```

Ensure pugixml is still linked:
```cmake
target_link_libraries(gdpdu_loadable_extension pugixml)
target_link_libraries(gdpdu_extension pugixml)
```

**Build verification:**

1. Configure: `cmake -B build -DCMAKE_BUILD_TYPE=Release`
2. Build: `cmake --build build --config Release`
3. Verify no compile errors
4. Check that gdpdu.duckdb_extension is created
  </action>
  <verify>cmake --build build --config Release succeeds</verify>
  <done>Extension builds with all components</done>
</task>

<task type="auto">
  <name>Task 5: End-to-end test with sample data</name>
  <files>None (testing only)</files>
  <action>
Test the complete import flow with the sample GDPdU data.

**Test procedure:**

1. Start DuckDB with extension:
   ```sql
   LOAD 'build/release/extension/gdpdu/gdpdu.duckdb_extension';
   ```

2. Run import:
   ```sql
   SELECT * FROM gdpdu_import('Gdpdu Data');
   ```

3. Expected output:
   ```
   ┌─────────────┬───────────┬────────┐
   │ table_name  │ row_count │ status │
   ├─────────────┼───────────┼────────┤
   │ LandRegion  │        XX │ OK     │
   │ Sachkonto   │        XX │ OK     │
   │ Sachposten  │        XX │ OK     │
   │ ...         │       ... │ ...    │
   └─────────────┴───────────┴────────┘
   ```

4. Verify tables exist:
   ```sql
   SHOW TABLES;
   SELECT COUNT(*) FROM LandRegion;
   SELECT * FROM LandRegion LIMIT 5;
   ```

5. Verify data types:
   ```sql
   DESCRIBE Sachkonto;
   -- Check BalanceatDate is DECIMAL(18,2)
   -- Check No is VARCHAR
   ```

**Error handling tests:**

1. Invalid path:
   ```sql
   SELECT * FROM gdpdu_import('nonexistent_path');
   -- Should return error status
   ```

2. Windows path format:
   ```sql
   SELECT * FROM gdpdu_import('C:\\gdpdu\\Gdpdu Data');
   -- Should work with backslashes
   ```
  </action>
  <verify>Import runs without errors; tables are created and populated</verify>
  <done>End-to-end import flow verified with sample data</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] src/gdpdu_parser.hpp and .cpp exist and compile
- [ ] src/gdpdu_importer.hpp and .cpp exist and compile
- [ ] gdpdu_import table function is registered in extension
- [ ] cmake --build build --config Release succeeds
- [ ] SELECT * FROM gdpdu_import('Gdpdu Data') runs without error
- [ ] All tables from index.xml are created in DuckDB
- [ ] Row counts in result match data files
- [ ] Windows paths (backslashes) work correctly
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- User can call SELECT * FROM gdpdu_import('path')
- Function returns result set with table_name, row_count, status
- All tables created and populated correctly
- Windows paths handled
</success_criteria>

<output>
After completion, create `.planning/phases/05-integration/05-01-SUMMARY.md`
</output>
