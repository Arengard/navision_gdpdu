---
phase: 08-batch-import-integration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/include/nextcloud_importer.hpp
  - src/nextcloud_importer.cpp
  - src/gdpdu_extension.cpp
autonomous: true
must_haves:
  truths:
    - "User can call SELECT * FROM import_gdpdu_nextcloud('url', 'user', 'pass') and get results"
    - "Table names are prefixed with sanitized zip filename (e.g. export2024_Buchungen)"
    - "Failed zip files are skipped and remaining zips continue importing"
    - "Result set includes table_name, row_count, status, and source_zip for each table"
    - "Function completes successfully even if some zips fail"
  artifacts:
    - path: "src/include/nextcloud_importer.hpp"
      provides: "NextcloudImportResult struct and import_from_nextcloud function declaration"
      contains: "import_from_nextcloud"
    - path: "src/nextcloud_importer.cpp"
      provides: "Batch import orchestration: WebDAV list, download, extract, import with prefixing"
      contains: "sanitize_zip_prefix"
    - path: "src/gdpdu_extension.cpp"
      provides: "import_gdpdu_nextcloud table function registration"
      contains: "import_gdpdu_nextcloud"
  key_links:
    - from: "src/nextcloud_importer.cpp"
      to: "webdav_client.hpp"
      via: "WebDavClient for listing and downloading"
      pattern: "WebDavClient"
    - from: "src/nextcloud_importer.cpp"
      to: "zip_extractor.hpp"
      via: "extract_zip for extraction"
      pattern: "extract_zip"
    - from: "src/nextcloud_importer.cpp"
      to: "gdpdu_importer.hpp"
      via: "import_gdpdu_navision for per-zip import"
      pattern: "import_gdpdu_navision"
    - from: "src/gdpdu_extension.cpp"
      to: "nextcloud_importer.hpp"
      via: "table function calling import_from_nextcloud"
      pattern: "import_from_nextcloud"
---

<objective>
Wire batch import from Nextcloud: list zips via WebDAV, download, extract, import each with table name prefixing, and return aggregated results.

Purpose: This is the final integration phase that delivers the `import_gdpdu_nextcloud(url, user, pass)` table function — the core feature of v1.1.
Output: Working `import_gdpdu_nextcloud` table function that batch-imports GDPdU exports from Nextcloud with resilient processing.
</objective>

<execution_context>
@C:/Users/Ramon.Ljevo/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Ramon.Ljevo/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@src/include/webdav_client.hpp
@src/include/zip_extractor.hpp
@src/include/gdpdu_importer.hpp
@src/gdpdu_extension.cpp
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create batch import orchestrator module</name>
  <files>src/include/nextcloud_importer.hpp, src/nextcloud_importer.cpp</files>
  <action>
Create the Nextcloud batch import orchestrator that wires WebDAV, zip extraction, and GDPdU import together.

**Header file (`src/include/nextcloud_importer.hpp`):**

Define `NextcloudImportResult` struct with fields:
- `std::string table_name` — prefixed table name (e.g. `export2024_Buchungen`)
- `int64_t row_count` — number of rows imported
- `std::string status` — "OK" or error description
- `std::string source_zip` — original zip filename (e.g. `export2024.zip`)

Declare function:
```cpp
std::vector<NextcloudImportResult> import_from_nextcloud(
    Connection& conn,
    const std::string& nextcloud_url,
    const std::string& username,
    const std::string& password
);
```

**Implementation file (`src/nextcloud_importer.cpp`):**

Implement `sanitize_zip_prefix(const std::string& zip_filename)` helper:
- Strip the `.zip` extension (case-insensitive)
- Replace any characters that are not alphanumeric or underscore with underscore
- Collapse consecutive underscores to single underscore
- Trim leading/trailing underscores
- Return the sanitized string (e.g. `"Export 2024.zip"` -> `"Export_2024"`)

Implement `import_from_nextcloud()` with this flow:
1. Create `WebDavClient` with the provided URL, username, password
2. Call `list_files(true)` to get zip files — if fails, return a single result with error status
3. Create temp download directory via `create_temp_download_dir()`
4. For each zip file from the listing (use skip-and-continue pattern):
   a. Call `download_file(file.href, temp_dir)` — if fails, add error result for this zip and `continue`
   b. Call `extract_zip(download_result.local_path)` — if fails, add error result and `continue`
   c. Determine the GDPdU data directory: look for `index.xml` in the extracted files list. If `index.xml` is in a subdirectory (e.g. `subdir/index.xml`), use `extract_dir + "/" + subdir` as the import path. If at root, use `extract_dir` directly.
   d. Call `import_gdpdu_navision(conn, import_path)` to import tables
   e. Sanitize the zip filename to get the prefix via `sanitize_zip_prefix(file.name)`
   f. For each `ImportResult` from the import:
      - Build prefixed table name: `prefix + "_" + original_table_name`
      - Rename the table using SQL: `ALTER TABLE "original_name" RENAME TO "prefixed_name"`
      - Create a `NextcloudImportResult` with the prefixed name, row count, status, and source zip name
      - Add to results vector
   g. Clean up the extraction directory via `cleanup_extract_dir()`
5. Clean up the temp download directory via `cleanup_temp_dir()`
6. Return aggregated results

Error handling pattern for step 4 (skip-and-continue):
```cpp
for (const auto& file : list_result.files) {
    std::string prefix = sanitize_zip_prefix(file.name);

    auto dl = client.download_file(file.href, temp_dir);
    if (!dl.success) {
        NextcloudImportResult r;
        r.table_name = "(download)";
        r.row_count = 0;
        r.status = "Download failed: " + dl.error_message;
        r.source_zip = file.name;
        results.push_back(r);
        continue;
    }
    // ... extract, import, rename, cleanup ...
}
```

Include headers: `webdav_client.hpp`, `zip_extractor.hpp`, `gdpdu_importer.hpp`, `duckdb.hpp`.
  </action>
  <verify>
Files `src/include/nextcloud_importer.hpp` and `src/nextcloud_importer.cpp` exist. The cpp file includes all required headers (webdav_client.hpp, zip_extractor.hpp, gdpdu_importer.hpp). The `sanitize_zip_prefix` function handles edge cases. The `import_from_nextcloud` function follows the skip-and-continue pattern.
  </verify>
  <done>
Batch orchestrator module exists with: NextcloudImportResult struct (4 fields), sanitize_zip_prefix helper, and import_from_nextcloud function that wires WebDAV -> download -> extract -> import -> rename with resilient error handling.
  </done>
</task>

<task type="auto">
  <name>Task 2: Register import_gdpdu_nextcloud table function</name>
  <files>src/gdpdu_extension.cpp</files>
  <action>
Add the `import_gdpdu_nextcloud` table function registration to `gdpdu_extension.cpp`.

**Add include** at top of file:
```cpp
#include "nextcloud_importer.hpp"
```

**Add new bind/init/scan structs and functions** following the existing pattern (model after the `import_gdpdu_navision` registration):

Define `NextcloudImportBindData` struct with fields:
- `std::string nextcloud_url`
- `std::string username`
- `std::string password`

Define `NextcloudImportGlobalState` struct with:
- `std::vector<NextcloudImportResult> results`
- `idx_t current_row`
- `bool done`

Implement bind function `NextcloudImportBind`:
- Extract 3 VARCHAR arguments: url, username, password
- Define 4 return columns: `table_name` (VARCHAR), `row_count` (BIGINT), `status` (VARCHAR), `source_zip` (VARCHAR)

Implement init function `NextcloudImportInit`:
- Get bind data, create Connection
- Call `import_from_nextcloud(conn, url, username, password)`
- Store results in state

Implement scan function `NextcloudImportScan`:
- Output 4 columns per row: table_name, row_count, status, source_zip
- Follow the same STANDARD_VECTOR_SIZE pattern as existing scan functions

**Register the function** in `LoadInternal()` at the end (before the closing `}`):
```cpp
TableFunctionSet nextcloud_import_set("import_gdpdu_nextcloud");

TableFunction nextcloud_import_func(
    "import_gdpdu_nextcloud",
    {LogicalType::VARCHAR, LogicalType::VARCHAR, LogicalType::VARCHAR},
    NextcloudImportScan,
    NextcloudImportBind,
    NextcloudImportInit
);
nextcloud_import_set.AddFunction(nextcloud_import_func);

loader.RegisterFunction(nextcloud_import_set);
```

The function takes exactly 3 arguments (url, user, pass) — no optional overloads needed.
  </action>
  <verify>
The file `src/gdpdu_extension.cpp` includes `nextcloud_importer.hpp`. The `LoadInternal` function registers `import_gdpdu_nextcloud` with 3 VARCHAR arguments. The scan function outputs 4 columns (table_name, row_count, status, source_zip). Push to GitHub and verify CI build passes.
  </verify>
  <done>
The `import_gdpdu_nextcloud` table function is registered and callable as `SELECT * FROM import_gdpdu_nextcloud('url', 'user', 'pass')`, returning 4 columns: table_name, row_count, status, source_zip.
  </done>
</task>

</tasks>

<verification>
1. All three source files exist and are syntactically correct C++
2. `nextcloud_importer.hpp` declares `NextcloudImportResult` with 4 fields and `import_from_nextcloud` function
3. `nextcloud_importer.cpp` implements sanitize_zip_prefix and import_from_nextcloud with skip-and-continue
4. `gdpdu_extension.cpp` registers `import_gdpdu_nextcloud` with 3 VARCHAR args and 4 return columns
5. CI build passes after push to GitHub
</verification>

<success_criteria>
- `import_gdpdu_nextcloud` table function is registered with DuckDB
- Function accepts 3 arguments: URL, username, password
- Function returns 4 columns: table_name, row_count, status, source_zip
- Table names are prefixed with sanitized zip filename
- Failed zips produce error rows but do not abort the batch
- Temp directories are cleaned up after processing
</success_criteria>

<output>
After completion, create `.planning/phases/08-batch-import-integration/08-01-SUMMARY.md`
</output>
